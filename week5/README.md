# 总结限流，熔断，降级的常用方式，重试的注意事项，负载均衡的常用方式。

## 限流：
* 目的：防止自身服务器达到能力极限，当并发请求达到一个上限的时候，丢弃多出来的请求。保证自动扩容启动前不会过载
* 方式：
	* 单机限流: 针对本机设定一个阈值，限制单位时间内请求数量
		* 优点：简单可靠，性能高
		* 缺点：机器数量变化需要手动调整阈值；无法应对流量不均匀
		* 实现：[令牌桶算法](token-bucket.md)； [漏桶算法](leaky_bucket.md)
	* 动态限流：[过载保护](overload_protection.md)。根据CPU, 内存等可动态调整|
		* 优点：不需要手动设置
		* 缺点：需要主动搜集指标；应用场景少
		* 实现：BBR<br>连接池
	* 全局限流：根据全局各个服务的重要性，流量大小，算力需求等指标设置限流阈值；每个节点定期取得最大流量上限，用单机限流算法本地限流 
		* 优点：不会因为流量不均误触发；机器数量变化不需要调整；应用场景丰富
		* 缺点：实现复杂；配置复杂 
	* 客户端限流：客户端根据服务端的请求成功率、latency等指标，通过降级等手段限流。
		* 优点：直接；无需使用服务端资源。
		* 缺点：需要客户端额外逻辑，不一定每个客户端都能实现。只能作为补充。
	
* 其他要点：
	* 按请求重要度限流
	* 拒绝请求（返回429）也有成本。
	* 对每个租户增加资源限制

## 熔断：
* 目的：从客户端发起，保护后端服务不被流量冲垮，丢弃准备发到服务端的一部分请求。也可以控制总体平均延迟。
* 方式：
	* 客户端统计总请求数和成功请求数
	* 当失败率达到一定阈值，阻断器打开，丢弃请求或者用其他降级手段阻止请求发到服务器。
	* 按照一定规律探测服务端是否恢复正常，如果是，逐步返回正常状态。
* 要点:
	* 请求总数要达到一定量。
	* 如果服务端恢复，请求放行需要逐步恢复，否则会出现大量锯齿。
	* 放行逻辑可以参考: https://sre.google/sre-book/handling-overload/#eq2101

## 降级
* 目的: 减少server端工作量来降低负载或者意外。比如丢弃一些不重要的请求，用静态资源替代动态资源。
* 方式：
	* 针对次要服务进行降级
	* 用缓存数据代替实时数据
	* 页面留空或者用其他能正常返回的结果替代
	* 用预先定义好的静态资源替换，比如用缺省值
	* 停止一些辅助功能，比如输入匹配，提示之类的服务
	* 全局手动降级应对特定事故
* 要点:
	* 设定降级操作介入指标。比如CPU，延迟等。
	* 定义好降级策略，需要前后端协调一致。
	* 预先准备降级资源，比如定期缓存数据作为副本。
	* 客户端模块化，非核心模块降级
	* BFF层聚合API时，对特定模块降级
	* 应该只针对意外情况触发。
	* 定期演练。因为降级行为正常情况下是很少触发的。

## 重试
* 注意事项：总体是防止重试导致流量雪崩导致server雪上加霜
	* 限制重试次数，基于统计正常流量，限定百分比来判断重试次数。
	* 随机化，指数递增重试周期。（防止集中重试）
	* 只在错误发生层重试。需要约定一个协议告诉上层这个失败的请求已经重试过了。（防止重试级联放大）
	* 对于业务不幂等的请求不建议重试或者谨慎评估重试逻辑。比如写操作有可能数据已经更新但是返回失败，重试可能导致重复写入
	* 前端可以把重试次数发给后台来做全局判定。

## 负载均衡
* 方式：
	* JSQ算法：轮询。无法看到服务端负载，无法合理应对不同成本的请求处理或者算力不同后端机器。
	* [p2c算法](https://ieeexplore.ieee.org/document/963420): 
		* 后端每个response header返回一些机器负载信息
		* client端根据后端机器负载，health，latency等指标对后端机器打分
		* 对新启动节点最小化放量，给时间预热
		* 对打分比较低的节点，使用统计衰减的方式让其打分逐步恢复，防止其永远分配不到流量
		* 如果latency超出预期，增加惩罚，降低其得分


